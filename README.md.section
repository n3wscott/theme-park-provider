# Theme Park Provider Architecture

This project demonstrates a split architecture where the Crossplane provider functionality is divided into two components:

1. **Provider Server (gRPC)**: Manages the actual external resource operations
2. **Reconciler Controller**: Watches Kubernetes resources and delegates to the Provider Server

## Architecture Overview

```
┌────────────────────┐        ┌───────────────────────┐        ┌─────────────────┐
│                    │        │                       │        │                 │
│    Kubernetes      │◄───────┤  Reconciler Process   │◄───────┤ Provider Server │
│                    │        │                       │        │                 │
└────────────────────┘        └───────────────────────┘        └─────────────────┘
    Stores CRDs                Watches for changes &            Implements actual
    and their status           runs controller-runtime          provider logic via gRPC
```

### Provider Server

The gRPC server implements the actual provider functionality:

- Listens on a configurable gRPC endpoint (default: localhost:50051)
- Registers handlers for different resource types (Ride, RideOperator)
- Processes incoming gRPC requests to manage external resources
- Returns connection details and status information

### Reconciler Controller

The reconciler watches Kubernetes resources and connects to the Provider Server:

- Uses controller-runtime to watch Custom Resources
- Creates gRPC streaming connections to the Provider Server
- Translates Kubernetes events into gRPC operations
- Updates Kubernetes resource status based on provider responses

## Running the Demo

The project includes a convenience script to run both components:

```bash
# Run both components in separate terminals
./run-demo.sh
```

You can also run them individually:

```bash
# Terminal 1 - Provider Server
export GRPC_ENDPOINT=:50051
./bin/provider

# Terminal 2 - Reconciler Controller
./bin/reconciler --provider-endpoint=localhost:50051
```

## Creating Resources

Once both components are running, you can create and manage resources:

```bash
# Create a Ride resource
kubectl apply -f examples/ride.yaml

# Create a RideOperator resource
kubectl apply -f examples/ride-operator.yaml

# Check status
kubectl get rides
kubectl get rideoperators
```

## Benefits of Split Architecture

1. **Separation of Concerns**: Clear division between Kubernetes interactions and provider logic
2. **Reduced Permissions**: Provider logic doesn't need direct Kubernetes access
3. **Independent Scaling**: Each component can be scaled based on its needs
4. **Isolation**: Provider logic runs independently from Kubernetes controllers
5. **Testing**: Components can be tested independently
